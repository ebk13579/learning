# Transcript

## Introduction to GraphQL

### Introduction

```md
    Hello and welcome to Building Scalable APIs with GraphQL.
    This course will not focus on WHY you should learn or use GraphQL, I'll assume that you've already formed your opinions about GraphQL, and you're thinking of actually using it in a production project, and you're here to learn how to do that.
    We will, however, cover the "WHAT" question about GraphQL.
    If this is the first course you're watching about GraphQL, this first module is for you.
    I'll tell you what GraphQL is and isn't and show you how it is different from other languages and API runtimes.
    Feel free to skip this first module if you are already familiar with the basics of GraphQL.
    I am also going to assume that you can program or can at least understand a written program.
    In this course, we will be writing JavaScript.
    If you've never written JavaScript before, you should probably take courses about that first.
    This course will not teach you databases, SQL, or NOSQL. However, we will be using them in this course, so some familiarity will be assumed here.
    We'll go through some example on MongoDB, and others on Postgres.
    If you haven't worked with databases before, you should probably take courses about that first.
    So what exactly is this course about?
    Using GraphQL.
    Building and consuming a GraphQL API and how to do that efficiently.
    The course will be beyond the simple example code.
    We will build a real API with real capabilities that covers many collections in a database.
    The collections will be related, so we'll see how to deal with join operations and how to handle problems like N+1.
    We'll also look at things like server-side caching and client-side caching.
    We're going to be using graphql-js, the JavaScript implementation of GraphQL in this course.
    We'll also use the Data Loader JavaScript library.
    Data Loader is a simple batching and caching utility, and I think every GraphQL server should use it.

```

### GraphQL Is a Language and a Runtime

```md
    The simplest thing we can say about GraphQL is that it's something we put between a front-end application client, and a backend data service.
    However, in this simple structure, GraphQL sounds unnecessary, but if you add more clients and more services to the picture, you can start to see the value of a single communication medium.
    When a client needs access to data from two services together, with GraphQL in the middle, it only needs to communicate with one GraphQL layer and not two different services.
    We will demonstrate this practical need in the API we will be building for this course, part of the data we're going to work with will be stored in MongoDB, and the other part will be stored in Postgres DB.
    Two different services with different APIs, but our clients do not need to worry about that fact. The only API they'll see is GraphQL.
    Being a data agent is just one aspect of GraphQL.
    GraphQL's strong type system and the hierarchal graph-based structure with which GraphQL represents data are two more important aspects and are part of what makes it different.
    GraphQL's declarative nature is perhaps the most important aspect about it.
    GraphQL clients are in control of the data they need.
    They declare it to the GraphQL servers, and the servers will comply as long as long as the declaration is valid and within their capabilities.
    Here is a simple example query to ask a GraphQL server about employee No. 42.
    These are the fields we're interested in--first name, last name, and email. The resource is potentially represented in a database somewhere with a table like this. Note how the GraphQL query asked for specific fields. We don't want the server to expose anything else besides firstName, lastName, and email. For example, we're not interested in the employee's birth date or hire date, so we don't ask for those fields, and the server will not respond with those fields, although they are part of the user resource. This is different than other APIs where we usually ask about ALL the information available for a single resource. Those APIs make clients over-fetch information that they don't necessarily need. A standard GraphQL server response would be a JSON object like this. The answer matches the request query. Every field in the query becomes a key in the answer object, and the key's value is that field's answer.
    A GraphQL operation determines the shape of its data response, and a data object can be used to easily construct a suitable GraphQL read operation that can be used to ask about that object.
    Let's take a quick look at the official GraphQL definition. Let me draw your attention to an important point about it. GraphQL is two parts. It's a language, and it's also a runtime. These two parts are very different.
    We can use the language to communicate "queries" for reading actions and "mutations" for writing actions.
    GraphQL also supports real-time data with subscription and a compositional style with fragments.
    The runtime has many parts.
    It has the type system of a GraphQL schema, and it can validate and execute any request.
    We can also introspectively ask it about its capabilities and supported operations.
    Zooming in on the language part now, let's talk about queries and mutations.
    To describe both queries and mutations we can use the generic term "operation".
    A GraphQL operation is just a simple string with optional "variables".
    We use variables, for example, in a mutation operation when we want to make it re-usable with different inputs.
    We write GraphQL operations in "documents" on the client-side, and then use an interface to send these documents to a GraphQL server.
    HTTP is a popular interface option, with which we can send these documents to a GraphQL endpoint like /graphql, with a body data parameter like "query," and "variables" parameter in case our document uses variables.
    The server can also use HTTP to send us back a data response in JSON format for example. HTTP is one option of many.
    We can, for example, use Sockets, or an SSH protocol, or a simple command-line interface that works with an executable binary.
    GraphQL does not have any preferences or dependencies on any communication protocol. GraphQL does not depend on HTTP verbs or status codes like other resource-based APIs that use HTTP.
    A GraphQL document can contain one or more operations; if it does contain more than one operation, we'll have to also tell the server what operation to execute from the list of operations defined in the document. Just like any other language, a receiver will not understand any communication written in GraphQL without first learning the language or having a translator who understands the language. This is why we need to build a GraphQL runtime as the first layer of our server-side stack. The runtime's job is to understand GraphQL documents and translate them for the other services in the server-side stack. We can add the GraphQL runtime to any existing data service or multiple data services. The data services layers will prepare the data for the request and hand it to the GraphQL engine, which puts it together and sends it to the client who asked for it. For example, the GraphQL engine can pass a request to a service that fetches information from a REST API or from a SQL server, or from Redis, or a combination of those. The runtime layer can be written in any language, and besides the execution logic that we define there, we also define a graph-based schema to declare our API service capabilities to all clients. Clients can then pick the capabilities they want from the big list we publish. This approach decouples clients from servers and allows both of them to evolve and scale independently. Every field we define in a schema has a type. For example, one field can be a scalar value with types like string, integer, or Boolean. Another field might be an object or any array of objects. Every field has a resolver function which can be used to map the field to its read logic. For example, a fullName field might have a resolver function that returns a string concatenated from the firstName and the lastName of the represented object. When a client sends a server a GraphQL request, the following happens in order: The server reads the input from the interface. With the HTTP interface, for example, we're looking for the query parameter, and other optional ones. The server then parses the query into an abstract syntax tree. For every node in the tree, the server invokes its resolver function, which potentially communicates with other data services.
    The resolver function can return either a scalar value or other objects whose types also have their own resolver functions. Nested resolver functions will be invoked in the tree order.
    The data services in the all these resolver functions will be asked partial questions about the data.
    The data returned from all these resolver functions will be merged together into a single object.
    The server then sends back that object as the response, for example, in JSON format.

```

### The GraphQL Editor

To understand GraphQL as a runtime, we first need to understand the GraphQL language itself. Fortunately, the language is simple and has many similarities to JSON, the JavaScript Object Notation. If you're comfortable working with JSON, you'll be speaking GraphQL in no time. We'll learn the language syntax and features in detail in the next module, but let me first do a quick demo of the basic features in a practical example that we can all relate to: GitHub. We'll use the excellent site GraphQLHub.com for this demo. As you can see, we can explore GraphQL with many popular APIs here, and you should totally do that after we're done exploring GitHub. GraphQLHub.com is a test site. If you can't access it at the time you take this course, you can use other GraphQL demo sites and apply the same concepts on those sites. For example, there is a demo GraphQL API that exposes Star Wars data. You can google that. Those demos are all open source and can be found on GitHub, which means you can also clone them and run them on your own machine. When you click on one of these popular APIs on the GraphQLHub home page, you get an in-browser editor, and it's already populated with a sample GraphQL query. This editor is another open source project from Facebook. It's called GraphiQL, and it's an interactive tool that we can use to experiment with and test our GraphQL operations before we use them in our applications. The left side of GraphiQL is where we define the operations, the left bottom corner is where we define any variable values if needed for the operation, and the right side displays the server response when we execute the operation. We can execute this operation with this play button. The server response in this API is a JSON object. GraphiQL has many features. My favorite of all is the intelligent type-ahead and real-time error highlighting. But we can also collapse and expand sections of both the operation side and the response side. We can use this Prettify button if we have a query with bad indentation. For example, we could copy a query that was generated on a single line to GraphiQL and make it readable using this Prettify button. And, finally, there is an automatically generated documentation about every GraphQL API that we can access using this Docs button. Take a moment to explore GraphiQL and get familiar with all of its features. This default example query uses many features of the GraphQL language like scalar fields, object fields, field arguments, and inline fragments, comments. We will cover some of these language features here and some of them in the next module. For now, let's explore the language syntax starting from scratch.

### GraphQL Language Basics

GraphQL's introspective nature allows tools like GraphiQL to have their auto-complete feature that's also context- aware in any part of an operation, including the empty document here before we even start writing an operation. When we start typing anything, for example, m, you can see how GraphiQL starts searching all the options that are possible at our current context and gives us a filtered list from that. Let's write a query operation. You can supply a name to any operation. A name is optional for a single operation but we should always provide it. This is, by the way, a general programming advice; avoid anything anonymous. Names are helpful, not just for readability, but more importantly, for debugging. After our query name, we write what's known in the GraphQL language as a selection set. Once we're inside a selection set, we will be in a new context, and the auto-complete will work on a completely different list. To peek into that list without typing, you can press Ctrl+Space (or Option+Space or Shift+Space if that didn't work). These are all the options we can write here in this context where the cursor is. We can use this introspective nature to explore the GraphQL API without looking at any documentation. Also, with this much client awareness of all the things they can ask the server for, it's easier to avoid errors. These names in this list are not being fetched from the server when we type. On startup, GraphiQL caches all the capabilities of the GraphQL server. We call the items in this first list "fields" in GraphQL. Since we're still on the root level of this GraphQL operation, these fields are known as root fields. When we ask a graph about some data it represents, we need to start somewhere on that graph. We start with one node and ask it what it knows. The root fields we see here are all nodes we can start with in our graph query. Since GraphQLHub.com supports multiple demo APIs, the root fields here are just the names of these APIs. In addition to these API names, it looks like we can also ask the server a meta question about GraphQLHub itself. The type system indicates that this is a string scalar value. It's a field for which the server simply has a string response. Let's check it out. That's it. This is a valid, complete GraphQL query operation with a valid response. In English, we just asked this server the question: What is GraphQLHub? And the server responded with: Use GraphQLHub to explore popular APIs with GraphQL. We already know this, so this query is not very useful. Let's ask the server about something else. Keeping the GraphQLHub field, we can add another field under it. Let's pick GitHub this time. Note how GraphiQL immediately puts an error indicator under the GitHub field. This is because our query, as it is now, is not valid, and we can hover over the GitHub field to see the reason. We'll talk about the types in the next module, but you can get a clue here that we need a sub-selection set, so let's do that. The query is still not valid, there is an error indicator under the closing curly bracket here. Let's try to understand that error: Expected Name, found, closing curly bracket. Name here represents any field name, so GraphQL is expecting us to type something before this closing curly bracket, and we can use the auto-complete list to see what we can type. Remember, we're not on the root level anymore, so the list of fields we can use inside this selection set will be different. We can ask for either a user field or a repo field. Sounds right for a GitHub API. Let's explore the user field. Again, this error will tell us at this point that we need another sub-selection. We didn't need a sub-selection for the graphqlhub field because that field's value was a scalar one. There is no ambiguity about what we need fetched for the graphqlhub field since it's just a string. The user field on the other hand represents an object, not a scalar value like a string or an integer. When we ask the server about an object, we need to be explicit about what properties of that object we're interested in. We can see a list of properties in the auto-complete list inside the user field selection set. It looks like we can read Id, login, company, avatar_url, and repos. Let's read id, company and avatar_url. The error marker is now under user, let's check that out: Field "user" argument "username" of type "String!" is required but not provided. The trailing exclamation mark in the string marks the value as required. We can't ask the server for a user object without something to identify which user we want. Logically we need to give the server criteria with which it can pick a user for us. This criteria could be something like the first user, a random user, or the user whose username is so and so. From the error message we got here, the last criteria is what seems to be supported by this API. Just like plain-old functions, we provide arguments to GraphQL fields inside parenthesis. The error message told us that the expected argument name was username, and the auto-complete can confirm that for us. GraphQL tries to be as close to JSON as possible, so the syntax for providing an argument value is similar to the object notation. We need to supply a valid GitHub username value here. Both the GitHub field, and the user field represent objects. They're sometimes also referred to as complex fields. On the other hand, the graphqlhub fields, as well as Id, company, and avatar_url, are all simple fields that represent a scalar value. It's important that you understand this difference. When we need to ask the server about a collection, like an array, the scalar/complex rule also applies. If the collection has only scalar values, we don't need a sub selection in the query. This API does not have an example of that. However, you'll rarely ever see that. A collection usually has objects like the repos collection here. You can tell that this is a collection from its type here. The brackets mean this is a collection of GithubRepo objects. Similar to what we did with user, we need to specify what fields from this collection's object we want the server to respond with. And we can check them out either by clicking on this type and seeing all the information in the Docs section, or by simply going inside a subsection and invoking the magic auto-complete. Let's ask for only the name of every repo to simplify the output. Unfortunately, I do most of my coding in private repos, so there isn't a lot of interesting stuff going on here, but these are basically the public repos I participated in under my GitHub profile. Note how the collection is represented with a simple JSON array of objects. For example, if I have this response as an object in a JavaScript application and I want to read the fifth repo's name, I can do something like response.data.github.user.repos Go ahead and explore all the other features in this API. For example, try to read the list of commits on the GraphQL specification repo under facebook/graphql. Pause the video here and write a GraphQL query that would ask for both the commit message and the date of every commit on this repo. Come back when you're ready to see the solution. Here's the query I used to get the requested information. We can actually write this data requirement in multiple ways depending on the shape of the answer that we want.

### Summary
In this module, we defined what GraphQL is, talked about how to write query and mutation operations in documents, how to send requests to a GraphQL server via an interface like HTTP, and how the server will respond with data in a format like JSON. Using GraphiQL, we explored some of the main features of the language like fields and arguments, and talked about scalar fields, complex fields, and collections. In the next module, we'll dig a bit deeper and continue talking about more advanced features of the GraphQL language like aliases, variables, directives, fragments, and mutations.

## GraphQL Query Language

### Introduction

Welcome back. The GraphQL Query Language is designed around flexible syntax that is easy to read and understand. In this module, we'll explore the language syntax and learn the different features it supports. We'll first talk about fields and types in more details, explore the use of GraphQL variables, see how to customize the server behavior with directives, and also with aliases. We'll talk about fragments which I think is one of the most important features to understand about GraphQL. And we'll end this module by exploring how to write and execute a GraphQL mutation operation.

### Fields

Let's start by talking about GraphQL fields. In the previous module, we explored the basic features of the GraphQL query language using the GraphiQL editor and the GitHub API service at graphqlhub.com. We wrote these two queries. The first reads a single GitHub user information including the public repos that user participated in, and the second query reads a single repository commit messages and their dates. We've only seen query operation so far. Remember that GraphQL also supports mutations. We'll see an example of that later in this module. Quick Recap: We can give queries names. In fact, since I've put these two queries in the same document here, those names will be handy. If you click the play button, GraphiQL will ask you which query operation you want the server to execute. The server will validate all queries in the document, but it will only execute the query you choose. GraphQL fields are all the names you see in blue. We have two types of fields here--scalar fields like graphQLHub, id, company, avatar_url and name, and we have complex fields like GitHub, user, and repos. The repos field represent a list of objects. Similarly, in the second query, we have scalar fields message and date, and complex fields GitHub, repo, and commits. The commits field represent a list of objects. GraphQL Fields (both scalar and complex ones), are modeled after functions. They accept arguments, and they return something in the response. On the server, we'll write actual JavaScript functions to determine the value returned by every field. We call these functions the resolver functions. For example, the resolver function for the graphQLHub field determined that it should respond with this string. The user field, determined that it should respond with a user object. The Id field determined that it should display the id property of its parent object, which is a user in this case. The user field accepted one argument, and it used that argument in its resolver function to figure out which user object to resolve with. Notice one thing about the types of the different fields in these example queries. Inside the most inner selection set, you can only use scalar fields. If you introduce a complex field on that level, you'll have to supply another selection set for it. Scalar fields are the basic types in a GraphQL schema. They represent primitive values like strings and integers. In fact, here are all the scalar types we can currently use in a GraphQL schema--integer, float, string, and Boolean. The GraphQL ID is a special one. It represents a unique identifier, and it's often used to re-fetch an object data. It appears in GraphQL responses as a string. The fields that represent objects usually have a custom type. For example, the user field has a GithubUser type. This is a type that this particular service defined in its schema, and it's a type that represents an object, and the object has these properties, and every property has its own type. This is one implementation that makes hierarchical querying possible in GraphQL. The collection fields, like repos and commits, are lists that contain objects of certain types. In the GraphQL documentation, here's an example of a type that is a list. The PersonType here represents an object, just like the GithubUser type. This person object has two sub-fields, parents, and children. Both of these sub-fields are lists of the same person type. Similarly, the repos field here is a list of GithubRepo objects, and we define its type in the schema as GraphQLList(GithubRepo). Note how types are not just for fields, but also for arguments, and for everything else we'll see in a GraphQL schema. Spaces, commas, and new lines are all optional in a GraphQL query. And they're used to only make the operation string more readable. They are completely ignored by the GraphQL parser on the server, and in fact, when we hit this Prettify button, anything extra will be removed.

### Variables

Did you know that we can use variables in our GraphQL operations? Our TestQuery works for a single GitHub user. However, we hardcoded the value of a username in the query string itself. This makes this TestQuery not so usable for other GitHub users. To make it reusable, we need to make it generic by using a GraphQL variable as the input for username. We use a $ sign and a variable name. I'll call this variable currentUserName. The variable name can be anything. A variable needs a scope, and just like everything else in GraphQL, it also needs a type. If we look at the error message under TestQuery, it says the new variable we used is not defined for this operation. We define it using the arguments for TestQuery itself. $currentUserName is a required string. The type has to match the type of the field for which we're using this variable. TestQuery is now a generic reusable one. If we try to execute the query now, GraphQL will complain because the required variable currentUserName was not provided. We provide it using a JSON object in the query variables section here. For example, we can supply currentUserName in this format to match the variables needed for our TestQuery, and we can execute it now. Using variables like this allows the clients to avoid any string building operations at runtime. The currentUserName value will most likely come from a certain source in our application. For example, it can be read from the location in the URL or from a user input. Instead of building a query string using string concatenation for this variable, we can just pass the variable to the executor as is with our generic reusable query.

### Directives

Sometimes using just the field arguments to customize the behavior of the GraphQL server execution engine will not be enough. For example, what if we had a special variable in our application, call it includeRepos, and we want to customize the GraphQL server response to only include the repos list when this variable is set to true, and completely omit the repos list from the response when the includeRepos variable is set to false. The best way to do this in GraphQL is with a directive. Directives can be used to alter the GraphQL runtime execution, and they are commonly used with variables to customize the response based on the variables values. Examples of built-in directives that should be supported by all GraphQL implementations are the skip and include directives. A directive is used with the @ sign; it has a name (like include or skip here). That name has to be unique. The directive also accepts a list of arguments, just like fields. For example, the include/skip directives accepts an "if" argument, which is a Boolean. A directive also has a list of locations where we can use it. Both the include and skip directives can be used on fields and fragments. Let's use the include directive for the repos field and supply our $includeRepos as the value for its if arguments. Of course the includeRepos variable has to be defined by the operation as well. It's a Boolean and it's also required because we used it in the directive. And there you go, when includeRepos is false, the server omits the repos list, and when it is true, the server includes the repos list in the response. The skip directive works similarly but with an inverse logic.

### Aliases

Let's talk about GraphQL aliases. Sometimes the data exposed by the server might have different property names from what the UI is using. For example, let's assume our UI uses a variable called githubid instead of just Id. Now we would have a mismatch between the server response, which has "id" as the key to this value, and the UI component, which expects the property to be "githubid." This usually means that we would need to process the server response on the client to make it match what the UI is using. But GraphQL aliases can help us avoid this extra processing. We can simply use an alias name in the query to rename the key used in the server response. githubid is id, and when we execute that, the response will be just ready for the UI. No further processing needed. We can use aliases on any field to customize its appearance in the response. Using this feature, clients have an extra level of control over the response, and they don't need to do any extra processing to the received data before they can use it. We can also use aliases to ask for the same field more than once. For example, if we want to read the information for two users in the same query, we can use aliases to distinguish between them. Here's a query that does exactly that. In here we are asking for two users, aliasing the first one as user number one, and aliasing the second one as user number two, and we used variables to make the user field actually fetch different users. The response used the aliases we provided instead of the original field name.

### Fragments

Fragments are what make GraphQL composable. Let's see how. In the last example, we repeated the user information fields in our TwoUsers query twice, once for every user. If we later decide to ask for an extra field on every user object, we'll have to change two places in our query, which is not ideal. We can use GraphQL fragments to refactor this repetition and compose our main query using a smaller query fragment that represents the fields on a GitHub user. We define a fragment using the fragment keyword and give it an identifying name and specify on which type this fragment can be used. For our example, we want to use it on a GithubUser type. Note how the autocomplete works here too. Inside the fragment root selection set, we can write any valid query node for the GithubUser type. Again, we can also use auto-complete to see our options. Our original TwoUsers query used the fields Id, company, and avatar_url, so we make this fragment do the same. And with this we can now remove the repeated information and instead represent it with UserInfo fragment. Note how GraphiQL is now giving an error that we have an unused fragment. Let's use it. A fragment is just a partial operation. We can't use it on its own, but we can use it and reuse it inside a full operation. To use a fragment in an operation, we prefix its name with the three dots operator. The response from the GraphQL server will be the same, but now we're using a fragment to compose our full operation. The three dots operator is known as the spread operator. When a GraphQL server sees three dots followed by a name anywhere in a GraphQL query, it will look for a fragment defined using that same name, and it will spread the content of the fragment in place of its three-dotted name in the query. The content of the fragment has to fit in the place where it's used. That's why our fragment, which was defined on an GithubUser object, can only be used within the selection set that expands a GitHub user object. Getting rid of repetitions like this is just one small benefit for fragments. The real benefit is in composition. Query fragments usually map one-to-one to the different components that compose a UI. Every component in the UI will have an associated GraphQL fragment in the document, and as we compose the full UI with its different components, we compose the full GraphQL operation with its different fragments. This allows different components to own the part of the overall data requirements that they care about, and it allows the top-level components to separate the data requirement specification responsibilities among different components. This isolation of responsibilities is helpful in maintaining, troubleshooting, and improving UI components. Fragments are used extensively in frameworks like Relay.js, which is built on this concept of declarative composable data requirements. If you'd like to learn more about Relay, Pluralsight has a course for that, and I hear it's good.

### Inline Fragments

Fragments are powerful. Inside a fragment, we can use any of the features we've covered so far, including variables, aliases, and directives. There is one other interesting way to use Fragments--inline. For example, I can copy this fragment definition without its name and spread it for user2 inline like this, and the query would still work as before. But you're probably asking yourself now, What's the point? And I'll be happy to answer that question with an example. Inline fragments are useful when we query a field that has multiple types. In GraphQL, we can define a group type which can be either an interface or a union of multiple types. We'll see how to do that in the next module. But those types basically allow us to combine multiple types for a single field. However, why would we need to do so? Sometimes objects have different types based on how we use them. In a company's people database, a person can be either an employee or a vendor. In GraphQL, we model this relation with an interface type. We say a PersonType is an interface, and both EmployeeType and VendorType implement this PersonType interface. Sometimes an object can be represented by one of two types. For example, the author of a GitHub repo commit can be a user of the GitHub platform or a guest user that does not have a GitHub username. But both of these types represent an author object. In GraphQL, we model this relation with a union type, we say an AuthorType is a union of both GitHub User, and a guest CommitAuthor. It can be either one of those. But given that the type GithubUser and the type GithubCommitAuthor have different fields, how exactly are we supposed to read a commit's author information? This is exactly where we can use inline fragments. Since inline fragments work on types, inside the author selection set, we can have one inline fragment for the GithubUser type, and another for the GithubCommitAuthor type. And within each type, we can specify the fields that are valid on that type. So let's read the login for a GithubUser and the email for a GithubCommitAuthor. In the response, GraphQL will include a login property if the author is a GitHub user and an email property for guest users.

### Mutations

Reading is just one of the four CRUD operations that a client can communicate to a server. Most clients will also communicate their need to update the date. With GraphQL, this can be done with Mutations. A GraphQL mutation is very similar to a GraphQL query but with runtime awareness that resolving this mutation will have side effects on some elements of the data. To demonstrate GraphQL mutations, I am going to use a different GraphQL API, the one behind rgrjs.com. This application is a list of resources for React, GraphQL, and Relay, and it's built with React, GraphQL, and Relay. I built this simple example application as a demo for another Pluralsight course. The code is open source and the API is public. Anyone can use this form to add new resources. If we navigate to /graphql, we'll get the same cool GraphiQL editor. This time, we're going to use it to write a mutation. We start our operation definition with a mutation keyword and give it a name. I'm going to use the documentation explorer to show you how to figure out what you need to do to get this mutation to work. You can also use the auto-complete. When we click on the root mutation type, we'll get a list of all the mutations supported by this server. For this server, we only have one mutation, createLink. Inside the selection set, we type createLink and add a selection set for that. We supply input to the mutation operation using field arguments. The createLink mutation expects a single argument, input, and that argument has a type of CreateLinkInput, and it's required. So we supply the mutation with an input variable, define it on the mutation operation as a required createLinkInput. To see the shape of this createLinkInput, click it. It has three strings--a title, URL, and a clientMutationId--and they are all required. Let's create an actual link resource. We supply a title and a URL, and the clientMutationId is a simple Id field. It gets added by Relayjs since this application uses Relayjs, but we can just send anything here, the server can echo it back if we ask it to. There is one more thing we need to do before we can execute, read something from the mutation payload. Go back to the mutation definition, and check out the CreateLinkPayload output type. Every mutation has input and output. The input is what the server uses to actually execute the mutation, and the output is everything we can read after the mutation has been executed. Clients usually need to read something after mutating data. For example, let's read the Id of the newly created mutation. The output exposes a linkEdge field, which has a node field, that has the new link information. Don't worry about edges and nodes. This too is coming from Relayjs but it's just a hierarchy to hold the resources data. A GraphQL mutation is just another function that gets resolved on the server, but it will do multiple things. The createLink function will first persist the link data that we receive through field argument to the database, and it will then read the database generated information about this new link and send back a response object ready to be used by the UI to display this newly created link. We can execute. This Id is actually coming from a MongoDB database so we know our brand new resource made it to the list. In fact, we can refresh rgrjs.com and see the new resource there.

### Summary

We introduced the flexible syntax of the GraphQL query language in this module. We've talked about GraphQL fields and their scalar and complex types and how to use field arguments and variables to guide the GraphQL executor on how to determine the field's response. And to further customize the behavior of the executor, we've seen how to use directives and aliases. We've learned about using fragments for composition of queries, and talked about inline fragments and their use with GraphQL interface and union types. And, finally, we've seen a mutation in action and used it to add a record to a database. In the next module, we'll start writing our own GraphQL schema and see how all the operations and features we explored here can be implemented on the server side.

## GraphQL Runtime

### Introduction

Now that we know how to speak the GraphQL language as a client, it's time to learn how to create a server that understands the same language. We are going to build a real data API for a naming-contest application. This is a simple application where users can create a contest to name something, like a book or a blog, or even a company. Ideally they'll offer some kind of reward for a winning name, and other users of the application can propose names and vote on names. I have implemented this application before, long time ago, and it's running under Bootname.com. It's mostly server-rendered HTML with a little bit of jQuery that uses a RESTful APIs. After designing the new GraphQL API for this idea in this course, I am hoping to rewrite Bootname.com at some point to actually use this new GraphQL API. To build an API, we first need to have some sources of data. We will be using two different databases in this course. Postgres, which is a free open source relational databases (it's just like MySQL, but much better). We will be using Postgres to store all of our transactional data. We'll also use MongoDB, the community edition, which is also free and open source. MongoDB is as NoSQL, document-oriented database. We'll use it to store aggregate information about our data, like counts and averages. It's not unusual to have a situation like this in a real project where you have to read data from multiple sources. Since we'll be using the GraphQL JavaScript implementation from Facebook, you'll also need to have the latest Node.js installed on your system to follow along. If you don't have Node, Postgres, or Mongo, you should stop the course here and go install them first.

### Loading Some Test Data

I've created a simplified database structure for the naming contest project and prepared some scripts to load some seed testing data for us to work with. Clone this repo from GitHub, cd into it. The master branch should be empty, but there should be branches for every clip from now on. Checkout branch m3-02 to get the starting point for this clip. Let's first make sure that you have a recent install of Node.js. Here's a little test for that, can you use arrow functions and template strings? If you can, you'll probably be fine, if not upgrade. This repo has some predefined npm dependencies. We'll need to run an npm install command to bring them in. Let's quickly explore this repo that we just cloned. It's a simple node project with some dependencies to work with Mongo and Postgres. You'll also notice that I added a dev dependency for nodemon. nodemon will help us monitor the node process for changes while we develop our server. This node project has a starting point under lib/index. This is where we'll mount our API server. Right now it's an empty file that just logs the node environment when you run it. We can test that using node lib/index, and you should see it running in development mode. The util file is where we're going to put generic utility properties and functions. Right now it only exposes the nodeEnv variable. I've also prepared some configuration scripts here. Those will be very helpful when it's time for us to deploy our server. Right now they have values for the development environment. Postgres connections will be for a "contests" database, and MongoDB is also expecting a local contests db. Let's take a quick look at the table structure we have for Postgres. We have a users table to hold users data like name and email, and also a simple api_key to authenticate users to our API. This is not the best secure mechanism to do so, but it's a good simple start for the purposes of this course. The contests table will hold contests information like a title, description and a status. The status will have one of these three values. A contest starts in draft mode, then it can be published, then it can be archived. The names table is where we're going to store names proposed by the users, and the votes on names can be either up or down. Notice how this simple structure is heavily constrained with primary keys, foreign keys, as well as nulls, unique, and other custom checks. These constraints are helpful in many ways. We can use them to better understand the design of this structure, and they will be the good guard if our API code tries to insert some bad data. This script will also insert some test data in those tables. The Mongo script is a simple one. It connects to local Mongo and inserts two records under a users collection. These two records reflect the counts of the test records we just saw for Postgres. User 1 has 3 contests, 0 names, and 4 votes. Having this data in Mongo will add a challenge to our task of building an API. When we need to query for both data rows and counts together, we'll have to ask two different services with different APIs. This will highlight one major advantage of GraphQL as an abstraction layer on top of all of our other services and backend logic. Before we execute the scripts that will load the test data into Postgres and Mongo, make sure these databases are both running and accepting connections. I usually test Postgres by running the psql command, it should be in the path like this. I run my local MongoDB with the mongod command, and I can also check with the Mongo command to make sure I can connect to it. Looks like everything is good. We first need to create the Postgres database, which we named contests. We can do so with the createdb command, and also make sure you can connect to the contests database, which should be empty at this point. Then to load the test data that I've prepared for Postgres, we can use the command psql with contests as the database, and use an input redirect from the script under the database folder. It's called test-pg-data.sql. This will create the four tables and insert the test rows into them. Don't worry about the warnings here, the script is designed so that you can rerun it to reset the data. When we connect to the contests db now, we should see four tables--contests, names, users, and votes--and those tables should all have some test data in them. If you're not comfortable with the Postgres command line, you can use a graphical interface like this one. I am a big fan of the command line, but it's much easier to navigate the schema in a graphical interface. To load the test data for Mongo, we need to execute the node script under the database folder. Making sure mongod is running in the background, run node database/loadTestMongoData.js, and that should insert two records in a users collection under a contests db. Connect to MongoDB with your favorite client, and double check that the data is there.

### our First GraphQL Schema

Let's do the mandatory hello world example for GraphQL. Basically, we want a server capable of answering a hello field with a 'world' string, just like in this screen shot here which I captured at the end of the next clip. The first thing we need is to define a schema. Let's place all our schema related code under a schema folder and make the starting point there an index.js file. In the index.js, we define a constant to hold our schema object, and we want to eventually export this constant so that we can import it from other places. The GraphQL JavaScript implementation has many type helpers that we can import here to help us define the schema. We can destructure them from the graphql package like this. I'll import GraphQLSchema, GraphQLObjectType, and GraphQLString. These are the three helpers we need for our hello world example. Our schema here would be an instance of GraphQLSchema. The constructor function in most of GraphQL classes takes a single configuration object. For a schema, the configuration object has two properties--query and mutation. We're not ready for mutations yet, so I am going to comment it out. Those two properties expect a GraphQLObjectType. Let's give it a RootQueryType constant, and let's go define it. It has to be an instance of GraphQLObjectType, which also takes a configuration object as the constructor argument. The properties we'll use for this object are name, which is a string, and fields, which is a plain old JavaScript object. The root query type is a special one. We are modeling our data after a graph, and to traverse any graph, we need a starting point. And there could be many starting points. We use this root query type to define the acceptable starting points on our data graph. All the fields we define here will be available on the top-level query selection scope, and that's exactly where we placed our hello field in this example requirement. The name can be anything. I'll just match the constant name here. And in the fields object, we want to define a hello field which is another simple JavaScript object that has two properties--a type and a resolve function. This syntax is the way to tell the GraphQL server to accept a "hello" field question on the top level of the query. And to answer that question, it should use whatever we return from the resolve function. Remember that GraphQL is strongly-typed, we need to define a type for everything. Our hello field's return value is a string. That's why we use the GraphQLString helper that we imported before. And you've probably guessed it, we're going to resolve this field with a simple 'world' string. That's it for our GraphQL Schema, this is a complete and valid schema. It doesn't offer much, but we have to start somewhere. So now we need to execute this schema object and test it. In lib/index.js, we first import the schema that we just defined, and then we'll import the GraphQL executor function from the JavaScript implementation library like this. This GraphQL executor function takes two arguments--a schema and a query. We have a schema, but we don't have a query. The query is something we want to read from a client. We don't have a client, in fact, we don't have a web server yet. But for the simplest test possible, we can just read the query from the command line argument when we execute this file with node. The arguments can be read using process.argv (which is a Node thing), and we want the third argument here (indexed 2) because the first two arguments are the executable and the file name. Now that we have both a query and a schema, we can have the executor validate and run the query against the schema. The executor returns a JavaScript promise object, so we can use a .then on it to see the result of the execution, and we can simply console log it for now. To test this example, we can run the file with node. We have a new dependency though on the graphql package, and we need to bring that in first. Once we have that, we can execute lib/index supplying a GraphQL query as the third argument. Our query is simply the hello field being requested on the top level, and the server will gladly answer that question because we told it how to resolve a hello field on the top root level. If we, for example, ask for a field that was not defined on the server, we'll get a really helpful error message that the field is not defined on that type.

### Setting up a GraphQL HTTP Endpoint

If you haven't been following along with the code, you can check out the current clip branch from the same repo to start from the exact point where we are now. You can also compare your code to the code in the clip branch to find any differences if you have problems. The repo has a git branch for every clip. After checking out the branch, npm installs the dependencies, and tests the lib/index script with a (hello) query. And you should see a response like this. We can't, however, tell our users to use the command line to consume our GraphQL API. So it's time to put our schema executor behind something more usable. An HTTP endpoint is a common choice. First, we need an HTTP server. That's really easy to do in Node. We're going to use the express framework to do that. We just require the express function and execute it to initialize an application. Then make the application listen on some PORT. Usually we should read this PORT from the environment. And I like to always have fallback defaults. The listen function takes a second callback argument where we can log a message on success. I'm going to remove this reading of a query from the arguments. We don't need that anymore because users will be sending us queries with an HTTP request. We also don't need to call the GraphQL executor here but instead call it once we have an HTTP request from the user. In Express, we define an endpoint route using a middleware with .use, which takes two arguments-- the URL endpoint for the route, and a callback function to handle that route's request and respond with something. Our handling of the request would be to extract the query, execute it against our schema, and respond back to the user using the execution result. There is a small helper library that can do these three steps for us. I'll import it under constant graphqlHTTP from express-graphql, and this constant will hold a function ready to be plugged into the express route. The graphqlHTTP function takes a single configuration object as an argument, and in that object we pass our defined schema and few other optional properties. I'll add one property that I think every GraphQL dev server should have--graphiql: true will give us the awesome GraphiQL editor right here on our local server. We have two new dependencies--express and express-GraphQL. We need to bring those in, then we can run lib/index.js to test. Server is listening on port 3000, and when we navigate there, we don't have a root endpoint, that's expected, but we do have a /graphql endpoint. And in there you should see the mighty GraphiQL editor. And this editor understands our defined schema. The only field we have so far is the hello field, the server response will show here as expected. For the rest of this module, we're going to be doing a lot of changes in our GraphQL schema. To avoid manually restarting node for every change, we can use nodemon and have it execute the same command for us. We can do it this way with a global nodemon install, and now node will be auto restarted on change. We can also put this command in an npm script like this and run it with npm run the name of the script. Let's now make some changes! Let's take a look at the documentation explorer for our GraphQL server. We only have a query root field. We can use the search box here to look for anything in the schema. Type in hello and you should see in the search results that we do have a hello field on the RootQueryType. Click that, and the explorer will tell us that hello is a string. There is no description about hello though, so let me show you how to add one. In the hello object, add a description property, and the value is just a string. We can actually use markdown here to make for better documentation on every field. Note how this documentation feature is part of the field definition and not a comment or anything. When we refresh our explorer now, we'll see the documentation rendered for the hello field. While the description property is optional, you should try to always put something there. It helps the user understand the GraphQL API while they're using it.

### Defining Custom GraphQL Types

Now that we have a skeleton for our GraphQL Server with an HTTP endpoint, it's time to dive in and start designing the API for our data which we have in Postgres and MongoDB. Here's our simple database structure visualized. We have a users table and that has an api_key field. Let's focus on this users table for now and have a simple query that can ask for one user's information if we know the API key. Given this test data that we have in users, we'd like to ask the GraphQL server a question like, What is the email address associated with this API key? I'll name the top level field here "me," assuming users who know the API keys will be asking about their information. This me field will need to have an argument so that we can pass the API key value to the server. Testing with a valid API key here, the server should respond with the first row in the users table. Let's go make that happen. The me field is a complex one because it represents a user object and not a scalar primitive value, so we'll have to tell the user what properties we're interested in about a user object, for example, email. The server does not know this me field yet so we should get an error if we execute this query now. Just like hello was a top-level root field, me is also a root field. In fact, I'm just going to replace this hello example field with the new me field. The type for this me field is definitely not a string, it's an object. But we'll need to define types for every property on that object. So I'm going to extract the definition of this MeType into a constant, and don't forget to give a good description for this new me type. This type also accepts an argument, and we need to make the server aware of it using the args property here. The args property is another object with the names of the expected arguments as keys, and their type definitions as values. We only have the key argument, and it's a string. The key argument is in fact a required string; we can't ask about this me field without a key. In GraphQL, we can use a type modifier to model this requirement. We just wrap the primitive type with a GraphQLNonNull call like this. GraphQLNonNull is another helper available in this library. To resolve this me field, we need to read a single user's information from the database. We'll come back to this later, but let's first define the MeType constant. Let's place this MeType in its own module. Although this requires a little bit more coding, it's a good idea to split the code into smaller manageable pieces. We'll place the types under a types folder. Create the types folder, and a me.js in there. We'll need to import the type helpers from the graphql-js library. We need the GraphQLObjectType helper. This whole module will be just an instance of this class. In the configuration of the constructor call, the name is 'MeType,' and the fields is on object. We'll be reading the fields from the users table, so we can define all the columns we have on users here. Let's start with two--the Id and the email. We can give the type GraphQLID for the id field. This is a special GraphQL scalar type to represent unique required values. The email field is a string. The email is actually a required string as well, according to our database design, it was a not null field. So we can wrap it with the NonNull GraphQL type modifier. We need to import the helpers we used. This MeType is ready. If you're like me, and you always forget commas and semi-colons, a tool you should definitely have in your build is ESLint. I've enabled eslint here and when I saved the file, it immediately pointed to a problem here because of the missing comma here. Fix and save, and I do have another problem, GraphQLNonNull is not defined because I have not imported it here. If, gun to your head, you were told to keep only one customization in your editor, you should pick eslint. The time it will save you is priceless. Pause the video right now and go find an eslint plugin for your editor if you don't have one. With the MeType defined, we can actually see how GraphiQL will start recognizing our structure, but the server will reply with null because we did not return anything in the resolve function. In fact, if we return some fake data here in the resolve function that matches the MeType structure, the server will use that object in the response, but we want this data to come from Postgres, which means we first need to connect to Postgres.

### Using the Context Object

To connect to Postgres, we need to import the node driver library. It's called pg, and it should already be defined in the package.json file. We'll need to create a connection pool using the configuration settings we have under config, which for development, points to the contests database. We'll read this configuration object with a require statement like this, then select the configuration for the current node environment. Then create a pgPool object using this configuration object. We're in the starting point for the project at lib/index.js. We need this pool object in our GraphQL schema. I could have defined it in this file here, but what if another file needs to connect to Postgres as well? It would be great if we can have this pgPool available every time we want to resolve a field from the database. GraphQL has a special feature for that. It's called the context object, and it's always passed to all the resolver functions as their third argument. The first argument is the parent object we're representing. This will be null for a root field like this one, for all other levels it will be useful. We'll see a usage for it in the next clip. The second argument is the values of this field arguments as passed in from the user. So we'll need to use this second argument which is usually named args to read the API key value from the user's GraphQL query. The third argument for the resolve function is the context object. This object can be passed down from the executor. To make that happen, we simply add a context property to the graphqlHTTP function argument, and this context is an object that can hold any property. For now, the only thing we need to have on this global context object is the pgPool constant. In the resolver function, we can now use the pgPool constant through the context object, and we can use the fancy argument destructuring here to access the pgPool constant directly. So now we have a pgPool to connect to Postgres, and we have an API key. And we want to execute a SQL query to read the user's information from Postgres using that API key. Let's do this task in another module, but we can design the way we want to use it here. I'll call this new module pgdb. It needs access to the pool connection constant, so I'll make it a function that takes pgPool as an argument, and return an object with getters and setters. And what we need here is to get a single user, and I'll need to also pass in the value of the API key for this getter. That looks good. Let's place this pgdb module under the database folder. Since we used it as a function, we need to export it as a function. It expects a pgPool argument, and it will return an object. In the returned object we can define this module's API, getUser function which receives an apiKey, and it should return the user's object. However, reading this user object from the database would be an asynchronous operation. But luckily GraphQL resolvers are okay with that. As long as we return a promise that will resolve to the expected object, the GraphQL executor will take care of that. The pg node driver we're using returns promises for all its operations. What we need here is a query read operation passing in a select SQL statement. We want to select * from users where the api_key is the value we passed to this function. This is one syntax this particular driver supports to supply values to the query. This call will return a promise that resolves to an object that has information about the rows returned by the SQL statement, so we'll need to modify the promise a little bit to return a single row directly. We can chain a .then call, and return the first row using this syntax. We know that this SQL query returns either 1 row or 0 rows for bad keys, so we're not losing any information here. Moment of truth, testing now, and the GraphQL server is responding with the data that we have in Postgres. We just handed the GraphQL executor a promise object, and it handled it for us. This is another major goodness in the GraphQL executor.

### Reusable Field Definitions

Let's complete the Me field. Since it represents a user, there are more columns in the user table that we should expose as well. We have firstName, lastName, and createdAt. Extending this field in GraphQL is straightforward. Just like id and email, we can add a firstName field, which is a GraphQLString. Easy right? Except that software developers are highly paid for a reason. There is always something unexpected. If we test this firstName field, the server is aware of it, but it returns null for it. Why is it that reading id and email was fine, but not firstName? We naturally want our API field to be all CamelCase. But our database columns are actually in snake_case. That's the convention in SQL land. Things worked for id and email because both of them are snake_case and CamelCase at the same time. To make sure that is the problem here, we can force the resolver function to read the snake_case property on the user object. The first argument for every resolver function is the object we're modelling. In this case, it's the user object as we read it from the database, which means we can make this new firstName field resolve with the first_name property on the object, and that would solve the problem. But we're going to have to do the same thing for lastName and createdAt, so doing it manually like that would get old real fast. I'll show you two solutions for this problem--a good one and a better one. The first solution is to use a plain old function to return this configuration object. For example, we can name it fromSnakeCase, and pass it the GraphQL type we want there. We can do the same call for lastName, and createdAt as well. We can write this fromSnakeCase function in our util library. It'll be a simple function that receives a GraphQL type helper and returns an object ready to be used as the definition for a GraphQL field. The object will have a type and a resolve function. The type is what we have in the argument, and the resolve function is where we'll read the snake_case property from the object. But this is a generic function that we just used on three fields, so we'll need access to the currently executed field name. This is where the fourth argument to resolve can help us. So far we've seen three arguments on a resolve function--obj, args, context. The fourth optional argument holds a lot of information about the current execution state. One property on this argument is the fieldname. This would be the field name in CamelCase, so we'll need to snake_case it before we can read it from the object variable. I am going to use a small library to convert from CamelCase to snake_case. One option here is the humps library. It's a simple one with a cool name. We just import it and use it's decamelize function on the fieldname. That should do for now. Of course humps is a new dependency that we need to install with npm, and it looks like we have another problem with this util library here. It's actually two levels up from this point. That made the server run fine, we can test now. We can query for firstName, lastName and createdAt, and they all give back valid data from the database. Remember this was the okay solution. In the next clip, I'll show you a much better one.

### camelCase allTheThings

While this method of using a function to return a definition object for the field worked okay for our example, it's not the best we can do. We still have to associate every field in our schema with this function, and that gets more complicated when we combine it with other logic. For example, what if the email field was email_address instead? We'll have to modify its call to include a function call to its custom non-null type. And what if we have a custom logic that we need to put in a resolve function in addition to dealing with case problem? It would be really nice if we can abstract this complete type object from the case problem and just use regular GraphQL syntax here. There is a trick that will allow us to do exactly that. Whenever we read an object from the database, we can process it and camelize all of its keys before handing it to the GraphQL executor. This way we'll do the conversion once and never worry about it again in GraphQL types. Let me show you how to do that. We don't need this function anymore, and we'll take the humps library out of here too, and go use it in the pgdb module. The humps library has a special function that processes an object and camelizes all of its keys, including nested ones. It's named camelizeKeys. So we just call it on the db-returned object, and it will camelize all the keys of this object once and for all. Test and make sure things still work as before, but now with a much better solution. We don't have to worry about the case problem anymore. In fact, let's say for example, we want to implement a custom fullName field, which is a string. We just drop into its resolve function and use normal CamelCased properties, and things will work just fine because all properties are now CamelCased from the point of view of the GraphQL executor.

### Modeling a One-to-many Relationship

This GraphQL API is starting to shape up. We have one major type, MeType, and we're using that type as the starting point in our data graph. We can already use the great features of GraphQL with this simple type. For example, here's a query to read two users information using aliases and fragments. But we've only modeled one table out of four, and we have not seen how to deal with relationships yet. We know that one user has many contests in the database, so how can we make this relation accessible through the API? This certainly depend on the access strategy; do we want an API user to see all contests, or just the contests they created? Let's go with the latter here. Maybe we can have a new complex field inside a me field to list all the contests for the current user. Here's a query that models this structure. We are asking for information from two tables here. Let's see how to implement that. Contests is a new field on the type Me, and it's a special one. It's an array of records. In GraphQL, we can represent an array of things using the GraphQLList type modifier. We call GraphQLList with an argument representing the type of the items in that list. For our case here, the items will each represent a contest object, so we'll need to create a new custom type for that. We'll name it ContestType. The resolve function for this contests field will read a list of rows from the database. We'll come back to this part later, but let's define the new ContestType first. GraphQLList is a helper we can import from graphql. We'll require ContestType from contest under this same level, which is for types, and in there, we import the usual from GraphQL. This will be a GraphQLObjectType, so we start there. We export an instance of this helper, give it a name and a fields object. The fields map to the columns we have in contests table, except for createdBy because we already know who created the contest returned by GraphQL here. We need to give each field a GraphQL type. Id is a GraphQLID, code, title, and createdAt are all required strings because they are not nulls in the database. Description is an optional string. The status column is an interesting one. It's a string but with only three valid values--draft, published, and archived. GraphQL has a special type for that. It's called an enum. Note how status is also not null, so we'll wrap this enum type in a GraphQLNonNull too. I'll put the status type in a ContestStatusType constant. Don't forget to import the new helpers that we used. ContesteStatusType lives under contest-status here on the same level. And in that file, we'll begin by importing the new special type from GraphQL, GraphQLEnumType, and that's what we'll export for the contest status type, an instant of GraphQLEnumType, give it a name and a values object. The values object list all the possible values for this enum. Every value get its own object like this. The keys of the values object are how we want these values represented in GraphQL queries, and these could be anything. The values here are how the enum values are represented in the database. If we have a database that represent this status with numbers, for example, this enum structure will be super helpful to make the API users deal with names instead of numbers. For our case, we're just making sure that GraphQL is aware of our constraint on a contest_status field. So I made a mistake somewhere that made GraphQL compiler complain here. This is not a syntax mistake, we've got that covered with ESLint. This is the kind of mistake that you will learn something from. A GraphQL schema must contain unique named types, and I've named this contest status type "ContestType," which is wrong. We already have a ContestType right here. This other one should be ContestStatusType. All types within a GraphQL schema must have unique names. The server is running okay now. Our API recognizes the new contests field, but it's still returning null there because we have not implemented the resolver yet. Let's go do that. I hope by now you memorized the important arguments of every resolver function--the parent object, the list of arguments, the context object where we exposed our Postgres pool of connections, and the fourth execution state object if you need it. We resolve with a call to the pgdb module. Let's name this new function getContests, and it will require access to the current object, which is the user. We need to import pgdb here, and the new function in pgdb receives a user object, and returns a promise. Select everything from contests where the created_by field equals to the current user id, which we can pass to the query using the argument object. Similar to what we did for getUser, we need to modify this promise to return the rows property, and we should also call camelizeKeys on this response. The humps library works for arrays as well, which is great. Note how we returned all the rows here because it's a list of contests, while the getUser promise returned a single row. We can test this feature now! The server will return an array of contest objects for the current user. Let's read all the fields of a contest to make sure--id, code, title, description, status, and createdAt, and we have them all. Note how the server responded with the uppercase versions of the status enum, while the database has lower case. The enum type did this translation for us.

### Reading Counts from MongoDB

Let's see how we can expose the counts information we have in Mongo under this API. We have contestsCount, namesCount, and votesCount. These three fields are for one user which we can identify with userId here. Under the me field, we can design the API to match the data, adding contestsCount, namesCount, votesCount in here. They're all not recognizable yet. Let's first prepare our server with a MongoDB connection. It's slightly different than what we did for Postgres. We'll first need to import the node driver. We also need the assert library, which is part of Node itself. We'll read the configuration for Mongo similar to what we did for Postgres, reading it for the current nodeEnv. To obtain a Mongo pool of connection, we need to call the connect method on the driver, passing it the configuration URL, and that would give us a callback with the pool object we need, error-first of course. We need to make this pool available for all resolvers, so we'll move our endpoint code and the server listen call to within the callback to make that happen. The assert library can be used to assert that we don't have an error. This will raise an error if we have one. And, finally, we'll need to pass the mPool object to the GraphQL context as well to make it available to all resolvers. Run the server to make sure things are okay so far. We'll need MongoDB running at this point, and it looks like the server connected to Mongo fine because we didn't get any errors. All right, let's prepare our database module first this time. Right under database, in an mdb.js file, we'll export a function that expects the Mongo pool object, and it will return an object with functions as props. The first function we need here is one that reads the user counts object, name it getCounts. It needs the user object to identify it, and I'll make it return one countsField--so either contestsCount, namesCount, or votesCount--passing the countsField here to use it. This method will be used by a resolver function, we'll make it return a promise. The syntax to read a single collection object from Mongo using the native driver is this, get the users collection, find a single document using the userId value coming from arguments. And this would give us a promise that resolves to an object with many counts, so we want to only return one property of that object, so we'll modify the promise to do so returning the property that we're interested in. This way we can use this same method for all three counts in our three GraphQL fields. In the MeType, we'll need to import the mdb module that we just wrote and use it, just like we're doing for Postgres. Then, we define our fields, contestsType is a GraphQL int, and we'll resolve it using the mPool object available in the context argument to resolve. The returned promise is a direct call to the mdb module passing it the mPool object and reading the getCounts function. The user argument for getCounts is the current execution object (which represent the user), and the countsField here is the contestsCount. Since this matches the execution field name, we can just read it from the fourth argument to resolve to make this resolver code reusable in all three fields. Now we can use the same code for namesCount and votesCount. Don't forget to import GraphQLInt, it's the first time we've used that, and now we can test. These count values are coming from MongoDB. How cool is that? This simple query is reading information from two different databases--Postgres for these fields and MongoDB for these. This is abstracted from the API users. They just use GraphQL syntax, and the server will put things together for them. Do you, however, see a problem in what we did with these three MongoDB fields? There is a big problem here. Every one of these three fields will make a separate connection to MongoDB, which is not necessary. We could have just connected once to Mongo and used the same data for all three fields. That's one of the big challenges in GraphQL. And in the next module, I'll show you how we're going to solve it.

### Summary

In this module, we've implemented a GraphQL server that reads data from two different databases--Postgres and Mongo. We started by preparing our environment with some test data that we inserted in both databases. We then created a simple GraphQL schema and made it available under an http endpoint. Then we learned how to create standard and custom GraphQL types to represent our data. We learned about GraphQLSchema, GraphQLObjectType, and GraphQLEnumType, and learned the primitive scalar types like GraphQLString, GraphQLInt, GraphQLId, and type modifiers like GraphQLList and GraphQLNonNull. We learned how to write the resolver functions and learned about their important arguments, including the context object, which we used to make our database pool available to all resolvers, and the current execution object, which can be used to read information about the current execution state. We've also seen how to deal with problems like case mismatch between the data service and the API service, and explored how to model a one to many relationship, and how to combine data from both Postgres and MongoDB in one query. In the next module, we'll finish implementing the API for the rest of our data structure including some mutations, and we'll also cover some advanced areas in GraphQL like working with data loader, database views, and union types.


## Data Loader and GraphQL Mutations

### Introduction

In the last module, we started the implementation of the GraphQL API server for this data structure. We've so far worked with two tables in Postgres and one collection in Mongo. In this module, we'll continue implementing the rest of the API for this data structure, and implement mutations to add a contest and propose a name on a contest. We'll also see how to solve the N+1 problem and avoid extra database queries in general in the GraphQL executor. We'll see how to work with database views and how to create and use Unions to model multiple GraphQL types under one type.

### Node's Cyclic Module Dependency

Let's model the names table in our API We'll start by defining a type object for it. Under type/name.js, import the usual from GraphQL. This will be a GraphQLObjectType, and we need to export an instance of that. The fields here map to the columns in the name table, so we have Id, label, description, createdAt, and createdBy. Id is a GraphQLID, label is a required string, description is an optional string, createdAt is a required string. CreatedBy in the database is just a number, but exposing that would not be very helpful to the user. What we need to expose here is the user object associated with the number. I'll show you here how we don't have to map the values to exactly what we have in the database. I'll override the createdBy field to have the type UserType, and we'll come back here in a bit to figure out how to resolve it. UserType represents a user object. Import the helpers we used from GraphQL, import UserType from a user file on this level. We already have a type that represents a User, but we named it MeType because so far we've only used it to represent the current user holding an API key. We can reuse this type now to represent the user who created the contest, but we should probably make its name generic. With this rename, the new NameType that we just defined will also use this UserType here for the CreatedBy field. Rename MeType to UserType everywhere we used it, and make sure the server is running. If we inspect our types now in GraphiQL, we should see UserType used for both the root me field and the new name type createdBy field. The relation we have in the database for names is that one contest has many proposed names. So we can structure a query that asks about a single contest to have a "names" field as well. The names field will hold a list of all the names on that contest. Under the contest type's fields property, add a new names field. Its type is a list of the NameType we defined. This needs to be resolved using a select SQL query from Postgres. We'll abstract that under a getNames method, and pass the obj here as the argument. Object here represents a contest so we can use it to read the contestId. We need pgdb and NameType. We also need an important comma here and GraphQLList. In the pgdb module, we add the getNames method. It receives a contest object, and its query is select * from names where contest_id is the passed-in contest Id. Finally, we need to resolve the createdBy field, which we want to override so that it represents an object and not a number as it is in the database. This means we'll have to use a query to read the user object from the Id we have for it, which is the actual createdBy value coming from the database. We'll need to do this in pgdb. We actually already have a method to get a user from the database if you remember, but that one uses the ApiKey to select a user. This new method here will use the user's primary Id column. I'll name this one getUserById, and rename the other one to getUserByApiKey to avoid confusion. Naming is hard as they say, and we'll rarely get things right the first time around. This whole API is to help people name things after all. Okay, getUserById is similar to getUserByApiKey but uses the primary key instead. Everything else is the same. If you're really good with Node.js, you might have noticed a problem with the code that we've written so far. This code will not run here for an important reason. I was waiting for this error to happen because it will make us understand an important change that we're about to do. How about you try and identify this problem on your own first? Debugging is your friend. Pause here and give it a shot. The problem we have is a cyclic module dependency problem, which is messy and not easy to deal with. Cyclic module dependency happens when module A depends on B, module B depends on C, and module C depends on A. In our example, module NameType depends on module UserType, module UserType depends on module ContestType, and module ContestType depends on module NameType. We can verify this problem in NameType since we have a cycle, and Node.js actually allows that, UserType here will not have finished executing when it returns because it also needs NameType. It will be an empty object because the default export was not done yet. This Node problem can be solved pretty easily for GraphQL types. Instead of using a plain old JavaScript object for fields, we can use a function that returns a plain old JavaScript function. It's an equivalent syntax but now with a delayed interpretation for the fields content. So if we stick the UserType require call instead this function, we'll avoid this cycle problem because we will not be immediately using this type. And as you can see, the server now runs fine, and the UserType will be the right object when GraphQL executes the fields contents after defining all Node modules. When we require this NameType, it returns an object that has a function for fields, the content of that function won't be invoked until later in the process. This trick is also commonly used when you need to have a field that references its own parent type, for example, an employee's boss is also an employee, so while you're defining the EmployeeType, you need to also use the EmployeeType to define the boss field. The function syntax here will allow us to do just that. In fact, this syntax is so useful we should just always use it no matter what. Testing now, under the contests field, we have a names field, and we can read the list of names proposed for every contest here, and all this data is coming from the database. Quick question: How many SQL queries do you think we're using in this GraphQL request? The answer is too many, we have what's called an N+1 problem here, and we'll fix it in the next clip.

### The N+1 Queries Problem

I've enabled SQL statement logging for my local Postgres install here. Every time our server opens a connection and execute a SQL query, we'll see a record for that in the log here. Let's see how bad our problem is. Execute, and we made nine SQL execution. Now that's not a very high number, but if you take a look at those statements, you'll see lots of repeated calls, exact statement, exact params. That's a waste. Also do you see how we have three queries for names? That's because we have three contests, and for every contests we're reading the names from the db. That's N queries (three in this case), one per contest, plus one query for the contest information itself. That's our N+1 problem right there. Same thing for the users by Id query. We're calling that four times, one for each name we have in the returned data. We do have four names in the database. This is a big problem, and we should never release the code like that. But what exactly would be a solution here? Caching, at least in the same session. If we've asked the database about user #1, don't ask it again, just use the previous value. This would solve some cases here but not others. If the N+1 queries are asking for the same user, yeah, caching would be good. But if they ask for different users, caching is not enough. And what we need here is batching. Delay the querying on the same resource until after we figured out all the Id's that we need information for. Then use a single query that takes a list of Id's and gives back a list of objects. Managing caching and batching manually would be a headache though. But thanks to the Facebook team, we have DataLoader to do that for us. DataLoader is a JavaScript library that we can use to manage the SQL execution operations and apply caching and batching on them when needed. It's a pretty small project that's really easy to use. A loader is a function that takes an array of keys and returns an array of values representing those keys. Then when we use the loader to load one or more keys, DataLoader will internally apply caching and batching when it can. The source code of this project is a good candidate for code-reading if you're into that. To use DataLoader, we need to convert our database getter functions to operate on lists instead of single objects to enable DataLoader to do batching. For example, getUserById operation, becomes getUsersByIds, and it takes an array of userIds. There are many tricks to make a SQL query return rows based on values in an array, the simplest of which is to use the ANY expression with the equal operator just like this. The select statement will return a row for every user who has an Id in our userIds array, which is great but not enough for the DataLoader requirements. We can return all the rows here to match what DataLoader expects but we still have two problems to solve. Can you identify them? First, if we have a value in the userIds array that does not have a row in the database, the output array will have less items than the input array. DataLoader will complain. Second, the order of values in the output array has to match the order of keys in the input array. Otherwise, we'll have wrong data. Let's write a single function to take care of both of these problems for every getter function we have. Replacing the simple one we have here, let's call the new one orderedFor. We need to pass it the rows from the database, the original input array, and the field in our data rows that matches the values we have in the input array. For this case, it's the primary key Id. This is the same field we have in the where clause. Define the orderedFor function with the arguments it expects. This function will do two main things. It will make sure we always have a value for each input value in the collection, and it will process the rows to make sure the outputted array has the exact same order of the input keys, userIds in this case. It will use the field argument to match a row to a value in the collection. It's not a super simple function, but can you maybe try to implement that on your own first? Here's how I'd implemented it. First we still need to camelize the keys because, well, that's what we decided to do on every database returned object, although maybe this part does not really belong in the orderedFor function, but I am just going to keep it here for now. So the data constant is an array of rows with no particular order, and we know that every row has the field property in it somewhere. We also know the rows field property value exists in the collection array somewhere. What we really need here is to start with the collection array, and map every value in it to a row from data or to an empty object if we don't have data for that value. This means we'll have to search the data array for the row that matches the current collection element. Whenever you have a repeated search operation, a dictionary structure is what you need. We can convert data to an object where the keys are the values of the field variable, user Id's for our getUsersByIds example, and the values for those Id keys are the rows that fully represent them. If we have this structure, then inside the map call here, our element select operation would be a constant time. This is a simple conversion to do with a loop, but I'll use a lodash function here because it's just an optimization. Let's call this new dictionary inGroupsOfField. It's the same data array but processed with the groupBy lodash function, and our identifying value here is the field variable. Inside the map operation, inGroupsOfField for the current element is what we need to return in the output. This is the constant time operation that replaced the previous search requirement. Let's put that value in a constant. This is actually an array of a single item for our getUsersByIds case. This is because we can always have multiple rows representing the same field, but not for this example. So I am just going to do a quick if statement here, if we do have an array, return its first element. Otherwise, we don't have a row in the database for this value, so just return an empty object. Fixing a few syntax problems here and there, thank you eslint! And I think this function is ready. This is a function that we should definitely test on its own before we use it. It's a clear input/output relation. I've done some testing for it off-camera and things looked good. So this makes our getUsersByIds function ready to be plugged into DataLoader. Before we convert the other getters, let's use this one and test what we have with GraphQL. We're going to setup our data loaders in lib/index.js, we need to bring in DataLoader first. And we also need the pgdb module here which I'll just call with the pgPool. Two new dependencies--dataloader and lodash. The reason we're preparing for DataLoader here in lib/index is because I want the loaders to be initialized per request and not global for all requests. The goal here is to minimize the queries a single request is doing and not to maintain a global cache, because, otherwise, things would be more complicated. The request lives in this line here where we mount our schema in the /graphql endpoint. But I'd like to set up the data loaders before we execute the schema here with a GraphQL query. To do so, we can convert this second argument here back to a normal express callback function and call the graphqlHTTP function inside of it. In express, callbacks receive a request and a response objects, and we want to call graphqlHTTP with those arguments as well. This code here is equivalent to what we had before, but now we have a callback function that we can customize. Anything we write inside this callback function will have the lifetime of the request itself. This is where we set up the loaders. We're going to have more than one so let's define them in an object. The first one is usersByIds. And to make our pgdb function into a DataLoader, we just initialize a DataLoader object with the pgdb function as the constructor argument. Then to make the loaders available for the resolver functions to use, we just make the loaders object part of the GraphQL context object. Fixing any syntax errors we have, server is running, and we now have a data loader ready to be used in all resolver functions. This is the loader to get users by Id's, so we can use it for the createdBy field here which resolves with a user object. We don't need the pgdb module here anymore because we have access to the new loaders object. And instead of this call here, we use our defined loader, and return a call to the load function, passing it the same user Id that we care about here. DataLoader will fulfill this load request with a user object from the database, and it will cache that object for the duration of the http request. Pgdb is not used anymore, and I think we're ready to test! Re-execute the query, and we're down to six queries now. Progress! If you inspect those queries, you can notice how we're now invoking the users by Id SQL query only once, while before DataLoader we invoked this query four times. DataLoader is an essential tool for GraphQL servers, it's a simple but powerful one. Pause the video now and try to convert the getUserByApiKey function to be used through a DataLoader. We first convert the input and outputs into arrays, getUsersByApiKeys, for a list of apiKeys, use the an ANY expression with the equal operation, and return the rows ordered for the input array, the identifying field here is apiKey. Let me convert all getters we have. The getContests function is slightly different than the two we've done so far. It already returns an array for a single user, which means if we want it to work with multiple userIds, we're going to have to make it return an array of arrays. I'll name this one getContestsForUserIds. We need to do the exact same changes we've done before on the first two, and we still need the rows to be ordered for the input array, using the createdBy field. However, the orderedFor call for this array of arrays output will have to be slightly different. The orderedFor is written for a single object here, as we've made an assumption that the users primary Id field, and the API key field are both unique and would only give use a single user per group. This is not true for contestForUserIds, a user_id will have many contests. I am going to add a fourth argument here, call it single object. When that's true, we'll have this function behave as it does right now, but if it's false, it will return an array for every input element including the empty case. This way we can reuse this logic for all getters, passing true for the getters where we want a one-to-one mapping, and false for the getters where we want a one-to-many mappings. The getNames getter is similar to getContests. It will take a contestIds array and return an array of arrays, one array of names for every contestId. So we can use orderedFor with a false argument for singleObject. Here's a quick homework for you. When you look at this code here, we can't guess what these arguments are for, especially this false one here. What exactly is false? Modify the orderedFor function and make its use of arguments more readable. This is all we need for the getters functions. Now we can use them to create more loaders for every request. We have usersByApiKeys, namesForContestIds, and contestsForUserIds. All of these are now available to all resolver functions. We can now replace any database call to Postgres to be done through DataLoader instead. In schema/index.js, we're doing a call to pgdb to fetch the user with the API key, get rid of pgdb, and load this user with the new data loader designed to work with API keys. In the UserType, we're fetching the user contest, kill pgdb and use the loader contestsForUserIds instead. The userId we want to pass in this case is obj.id as object represents the user in this context. In the ContestType, we want to load the names array through the loader we prepared for them, passing obj.id here as object represents a contest. The syntax here needs a .load, and I think we can test now. All the data is there as before, but now, we're down to four queries. Remember we started with nine. What we have here is a query for each loader, one for the usersById, one for the usersByApiKey, and one for the contests table, and one for the names table. Note how the one for the names table is actually loading all the names relevant to our three contests in one query here. So instead of N+1 queries, we only have two queries now. Imagine a contest that has 100 names. Using DataLoader here is a big difference. Even if we changed our GraphQL query into a complex one that asks for duplicate information, for example with aliases here, DataLoader caching and batching would still limit the SQL connections we actually do and make only the minimum needed.

### Avoiding Extra MongoDB Connections

Just like we replaced our SQL connections to Postgres with data loaders, we can do the same for Mongo because we do have extra MongoDB connections here that we can avoid. This is not really an N+1 problem, but more of unnecessary connections problem. Let's try to enable logging for MongoDB connections to see the problem. This is really easy to do with the MongoClient we're using. Just import the logger object and call .setLevel debug on it. This will turn on a lot of debugging though, so we can filter it to only show the logs coming from the Server class. This way, we'll see a log line every time there is a server connection. Execute the GraphQL query, and here you go--three server connections happened here, although they all asked for the exact same information. DataLoader can help us avoid that by simply caching the first request and reusing it. All we need to do is convert the Mongo getters to work with DataLoader. Instead of getCounts here, we'll make it getUsersByIds. This will receive an array of userIds and return an array of user Objects. The syntax to do that in this Mongo driver is to use find instead of findOne, and we can do a $in operation here. And we need to call toArray to convert this find call into a promise. However, we still have to do the orderedFor trick here as well because, otherwise, the order is not guaranteed. I can actually show you what I mean with an example here. In lib/index, import the mdb module and call it with the mPool variable. Then call the getUsersByIds with 1 and 2. We have test data for those, and we can use a .then call here to console.log the result. Although that did not work because it's a small case d here. Our test call ran and our getUsersByIds worked great. The output was an array of users mapped to the input we have, 1 and 2. But what happens if I change the order of the input array? Mongo will still return 1 first, then 2. That would be totally wrong for DataLoader. Also, what happens if my input has an Id that Mongo does not have? I now have a mismatch, three elements input, two elements output. This is exactly why we wrote that orderedFor function. I'm going to leave this test call here to show you what orderedFor is going to do for us. So we need to modify the promise here, and instead of rows, we want to return those rows ordered for the userIds array. The identifying field in this case is userId, and this is a singleObject order here. We defined orderedFor in the pgdb module though, so it's time we move it to the util library so that we can use it in both Mongo and Postgres. I'll import here from util, take it out of pgdb, and put it in util. We'll need to bring its dependencies as well. Now take a look at the output of our test call. We have three elements in the output, and they are in the correct order matching the input. Now we can use the getter with a DataLoader. I'm going to add an mdb property to the loaders object to host Mongo loaders. We have a usersByIds loader that reads from the mdb getter that we just tested. In the UserType, we'll get rid of the mPool object here, and replace it with loaders, so we can now resolve all the methods with a call to loaders.mdb.usersByIds.load(the user Id). And we need to modify the result, which will be a user object, and return the fieldName on that object. The fieldName will be the relevant count here. Mdb is no longer used, so we can get rid of that. And now we can test. Execute the same query. We have the data as before, but now we're making a single connection to the MongoDB server.

### Using Database Views with GraphQL

The last table we have in our structure is the votes table. The votes themselves are not that interesting, what we should make readable here is a votes count. Votes are on names, so under the names list, let's design our API to have a total votes object under which the API user can read total up votes and total down votes. Under types, create a new module for the new total-votes type which is going to be a GraphQLObjectType. We'll also need GraphQLInt here to represent the up/down counts. Export an instance of GraphQLObjectType, name it TotalVotes. Fields is a function that returns an object. We have up, which is an integer, and down, which is also an integer. That's it for this simple type. Let's import it for the NameType and create a new field under name like we designed it. This totalVotes field will have the type that we just defined. And for the resolve function, we want to have a new loader that reads totalVotesByNameIds. That looks good, let's go define that loader. So totalVotesByNameIds will read from a getTotalVotesByNameIds function on pgdb. The votes are all in Postgres. Let me cleanup the logger lines here. We don't need those any more. In pgdb, create this new getTotalVotesByNameIds function. It receives an array of nameIds, and we'll need a query to select those vote counts. Since we only have votes transactional data, we'll need to issue a special type of query to actually calculate the counts. But this is where we can use a database view. We can define the logic to do the counting in the database view, and just use it here exactly as we use other tables. If we have such database view, we can just select the up/down counts for every name we have, and then do the usual to get the rows ordered for DataLoader. Let's call this database view total_votes_by_name. Here's the structure of the votes table, the up column can either be true or false. So let's write that special SQL query to count up/down votes for every name. We can easily do this with sub queries. We can start by selecting from names, because we want a row for every name, but we really only need the name Id here, so select Id aliased as name_id. Then we'll have a sub-query to count the up votes for that name, and another to count the down votes. To count the up votes, we'll select count of up from votes limiting the votes to the one for the current row name Id and only the up true votes. The down votes are exactly the same but with up = false. This is the exact data that we want for our defined getter in pgdb. So all we need to de here is to create a view from this select statement. So we do create view, the name of the view, as, the select statement. And now we can test. TotalViews have the up/down counts now, and that data is being read directly from a database view. I use database views when the logic I want to put in the view is unlikely to change, and also to join multiple tables together so that we do less SQL connections to the database.

### Working with Mutations

Let's give a GraphQL API user with a valid API key the ability to create a new naming contest with our GraphQL API. We do that with mutations. Just like we defined a root query type that held all the root fields that we can start with, we define a root mutation type to hold the root mutations that we can invoke. The RootMutationType is a GraphQLObjectType with a name and fields, exactly like a query type, but this time the fields will be commands. For example, we can have a command to add a contest, and another command to add a name to contest. I'll define the AddContestMutation under mutations folder. In there, create an add-contest.js to hold the definition of this mutation. Start by importing the usual from GraphQL. We're actually going to use a new helper here, GraphQLInputObjectType. GraphQLInputObjectType is similar to GraphQLObjectType but with some restrictions to make it suitable to represent a structured input. We'll use it to define the input structure for a new contest. What we need to return here is a plain-old JavaScript object because we used it as the configuration map for our mutation field. Just like a normal GraphQL object, we need a type, args, and a resolve function. The type of this configuration object is special. It's what we want to enable the users to read after we're done with the mutation. This should match the resolved value in the resolve function. It makes sense after inserting a contest in the system to read that inserted contest information. For example, what serial Id was given to it, what default values did the database use for our missing columns. Let's use a ContestType here as the type for the mutation configuration object. The args is where we define the different arguments for a GraphQL mutation. This is where the user will send us input values. We can use any primitive scalar type here, but we opted to do a structured input instead, so the only input argument here will be an input object, which is required. Let's call it ContestInputType. We used ContestType so we need to bring that in first. To define ContestInputType, we use an instance of GraphQLInputObjectType. Just like objects, this requires a name and a fields object. In the fields object, we need to list all the input values that we need from the user to be able to create a contest. This should be at least all the non-null columns in the database. But we first need a valid apiKey to identify the user who is creating this naming contest. Then the minimum we can go with here is a title and description. Other columns on the contests table have default values or not required, except for code. So need to derive a unique code for this contest, but we can just slug the title for that, for now. The apiKey input field is a required string, and so is the title field. The description field is an optional string. We need to import the helpers we used--GraphQLString and GraphQLNonNull. Next, we need to implement the resolve function. This function is special in mutations. It will do two operations--persist the contest to the database using the input arguments, then resolve with the newly persisted contest. Let's see how to do that. We need the resolve params, object, then the destructured input argument, and we also need the pgPool connection object. We need the pgdb module as well. We don't need DataLoader here because this is a write operation. DataLoader is only for read operation. Let's name this pgdb setter method addNewContest. And it will need access to the structured input object. This mutation configuration object looks good. Let's go implement our pgdb setter now. AddNewContest receives an input object. Let's destructure it here to the three variables we have--apiKey, title, and description. This function needs to return a promise that persists the contest and returns it. Luckily, we can use a single Postgres SQL statement to do both of these actions. We need a regular insert statement, code, title, description, and created_by. We can use direct primitive values for the first three but created_by is something that we need to read from the users table using the apiKey. We can use a subquery to do that, selecting the Id from users where the api_key is the variable value we have. This promise will simply be rejected if we try to add a contest with an invalid api_key as the created_by field is required, and it's also a foreign key on users. In Postgres, there is handy feature for insert statements. It's called returning, and we can use it to select any field from the persisted object after the insert operation is done. So let's just do returning *. Pass the variables in the order we used them. For code, we will slug the title, we don't have a slug function yet, so we'll need to write one. Now, for the response, we need to modify the promise to return the first object from the rows list. And don't forget that this is where we abstract the CamelCasing of all the keys so that we always use CamelCase in GraphQL. Let's import the dependencies we used. We need humps, and we need a slug function, which I am going to put in the util module. Making sure we don't have any syntax issues, looks good. Slug can be just a simple function that takes a string and LowerCase it first. Then replace all spaces and non-word character with a dash. This code is what an API user can use in the URL to identify the contest in an SEO-friendly way. So I think this is good enough for that purpose. I think we can test. In the documentation explorer, we should now see a mutation root field, and we should see our AddContest mutation, which receives a structured input object and resolves with a contest. This should really be Contest here, not ContestType, so I'll do that cleanup in the next clip. The contest input has three strings, two required and one optional. We request a mutation operation using the mutation keyword. We can give it a name and define the required input it needs. We'll use a GraphQL variable here for the input values. The actual mutation field is AddContest. It will receive this input variable as argument. And when it's done, we want to read few things. The auto-complete here will give us all fields available on a Contest Object, because that's what we made the mutation returns. Let's read Id, which should have some serial value from the database after the insert operation, code, title, description are all derived from the input, and status has a draft default value. We can supply the input values using the query variables editor here. We have input, which is an object, and in there we have (note the auto-complete here) apiKey, and let's use a valid one, and let's pass in good values for the title and description. And now we can execute. We know this operation worked because we are getting the serial value and some default values from the database. And note how the status field used the ENUM value, not the actual value in the database because that's something global for every contest. Let's check the database table. And the record is there. The createdBy field was correctly populated using the sub-query we used. Now I need to wrap this up to go watch the 4th of July fireworks, so I'm going to give you a quick homework here, and I'll have a solution for you in the GitHub repo, but don't cheat. Create a mutation to propose a name on a contest. Here's how I'd like our API users to invoke it: mutation ProposeName, uses a NameInput variable, the mutation AddName takes that variable as the input argument, and inside the mutation, we can read the information of the newly proposed name including totalVotes, which should have 0 counts here. Here's an actual test--the input needs an apiKey, a contestId, a label (which is the proposed name), and an optional description string. The input NameType is a required one. Execute, and the mutation should persist this name, associate it with contestId 6, and return a full name object. The name should be in the database table here. The code for this mutation is in the repo.

### Working with Unions

The last feature I want to show you is working with unions. But before I do, I've done some cleanup on our code so far. I made all fields configuration objects into functions, and made the naming of types consistent without a type suffix. If you checkout the branch for this clip, you should see these changes. Here's a simple query from our API to load the current user information. What if we want to give our users the ability to read all their activities in the system. For the purpose of this example, we'll assume an activity is when they create a new contest or propose a name for a contest. This activity type groups two types in our system together. It could be either a contest object or a name object. This is where we can use a GraphQL Union Type. Let's see how to define that. In the UserType module, we'll need to add a new field on a user object, activities. Activities is a list of, well, either a contest or a name. I'll name this type ActivityType to make it generic. Resolving this field is going to be challenging because we'll have to read information from two different tables that have different columns. Let's get back to this part later. First, we need to define this new ActivityType, which we'll place under the same level here. In activity.js we're going to import GraphQLUnionType from GraphQL. This module will be just an instance of GraphQLUnionType. We give it a name and a list of types. For our example, this union could be either a ContestType or a NameType. The union type configuration has a resolveType function. This is what GraphQL uses to determine which type the current object belongs to. It receives the object as the value argument here. We need something to identify the type for every object in this union, so let's assume that we have a property activityType on every object and that will determine here if we should return a ContestType or a NameType. Let's import the types we used here, fix any syntax issue, this should be types not type. Looks good. Let's go back to resolving this activities type. This is a read operation, so we should use a data loader for it. Let's call the loader activitiesForUserIds, and load it for the currently executed user object. Define this new loader here. The pgdb function name is getActivitiesForUserIds. In pgdb, getActivitiesForUserIds is a function that receives an array of userIds. Invoke a SQL query to read both names and contests for every user. We can read data from two tables using a database union operator, like this, which is what we want here but there is a problem. You can only union select statements that select the exact same fields. But we do have different fields here, so I am going to use a cheap trick here. I'll select the fields I care about from both tables, and for the different fields, I'll just fake it. Empty title on name, and empty label on contests. We can also add the activity_type field here since we used it the union definition to identify the type. And once we have a response from the server about these rows, we'll need to order them for the input userIds array. Rows are identified by the createdBy field. That was a lot of code, let's review. In lib/index, we defined our request-scoped loader, activitiesForUserIds. In getActivitiesForUserIds we used a database union operator to select data from two different tables. There is a missing comma here. We returned the rows ordered for the userIds array so that the function works as a data loader. In the UserType, we defined an activities field, which is a list of the new ActivityType, and we used the new data loader to resolve it, and we used the activityType property on every object to determine which type the current object is. We can test now. If we explore the defined type and look for activity, we'll see how it can either be a contest or a name. To read fields on an activity, we can use inline queries, and do something like this. When the activity is a Contest, read its title. And when it's a name, read its label. The data returned from the server will have mixed content, both names and contests are returned for the current user. Of course if we want the response to be consistent, we can still use aliases to rename the different fields here. This is a query suitable to display an activity stream on the user's dashboard.

### Summary

In this module, we added features to the naming contest API, we saw how to deal with Node cyclic dependencies problem, then we saw how to fix the N+1 queries problem with data loader and how to avoid extra queries in general with data loader. After that, we learned how to utilize the powerful database views with GraphQL and used a view to count the numbers of up votes and down votes on every name. We then learned how to write a simple mutation that writes then reads data from Postgres. And after that, we learned how to group multiple types together using a GraphQLObjectType. I hope you've enjoyed this course and what you learned here will enable you to build large-scale APIs using GraphQL and DataLoader. If you're interested to learn more about GraphQL and how to change GraphQL endpoints to make them Relay-compliant, I've written a book about that. I'd love to hear any feedback on either this course or the book if you read it. Thank you for watching!


















